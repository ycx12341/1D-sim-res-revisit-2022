#Source companion functions
source("PDE_GradientMatching_Functions.r")
#Load the package "tictoc" in order to measure the computational time.
library(tictoc)
setwd("~/Academia Yunchen/Gradient matching revisit 2022")
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#Load the package "tictoc" in order to measure the computational time.
library(tictoc)
#Load "readr" package for writing results - just check it's loaded
#(it's actually used first inside the parallel routine)
library(readr)
#Load packages for running the simulation in parallel
library(doParallel)
library(doRNG)
#Define simulation parameters
#Measurement error CV levels to run (if a scalar then just runs at this one level)
cv <- c(0.01, 0.025, 0.05, 0.075, 0.10)
#Measurement error distribution
dist = "gamma"
#Number of simulations at each level of CV
n.sims <- 200
#Whether to save simulation outputs to file or not
# (useful as they are time-consuming to run, and this
# allows further post-processing on results)
save.sims <- TRUE
save.sims.dir <- "SimRes_ests"
#Set random number seed so results are reproducible
# (random number set within each level of CV to make any repeat runs of a
#  single CV level easier)
rn.seed <- 874513
#Number of parallel threads to run on
n.threads <- detectCores() - 1
# Define model parameters
dn <- 0.01
gamma <- 0.05
eta <- 10
dm <- 0.01
alpha <- 0.1
rn <- 5
# This parameter not included in the optimization
beta <- 0
# Make a vector to store the true values
true.values <- c(dn, gamma, rn, eta, dm, alpha)
names(true.values) <- c("dn", "gamma", "rn", "eta", "dm", "alpha")
# Define 1D dimensionless space points
n.x11 <- 80
max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
# Initial values
n <- n0
f0 <- 1-0.5*n0
f <- f0
m0 <- 0.5*n0
m <- m0
#Generate reference dataset
ref.data <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0)
data.dim.row <- length(ref.data$n[, 1])
data.dim.col <- length(ref.data$n[1, ])
#Truncate the reference data set to avoid generating gamma errors at data values of 0
ref.data.trun <- list(n = ref.data$n[2:(data.dim.row - 1), 2:(data.dim.col - 1)],
f = ref.data$f[2:(data.dim.row - 1), 2:(data.dim.col - 1)],
m = ref.data$m[2:(data.dim.row - 1), 2:(data.dim.col - 1)])
#Use start values from manuscript
start.values <- c(0.01, 0.133, 6.25, 12.5, 0.0166, 0.125)
#Record degrees of freedom for sd calculations
n.data.trun <- sum(apply(sapply(ref.data.trun, dim), 2, prod))
n.params <- length(start.values)
df <- n.data.trun - n.params
if(save.sims) {
if(!dir.exists(save.sims.dir)) dir.create(save.sims.dir)
}
cl <- makeCluster(n.threads)
registerDoParallel(cl)
cl <- makeCluster(n.threads/2)
registerDoParallel(cl)
tic()
for(i in 1:length(cv)) {
#Run the simulation in parallel
ests <- foreach (sim = 1:n.sims, .combine = rbind) %dopar% {
#Introduce random error
pert.data <- perturb.reference.data(ref.data.trun, cv = cv[i], distribution = dist)
#Obtain gradient approximations
grads <- approximate.gradients(pert.data, x11, max.t, distribution = dist)
#Estimate parameter values and associated sds
res <- optim(start.values, calculate.sse, grads = grads, hessian = TRUE,
control = list(maxit = 20000, reltol = 1e-11))
par.ests <- res$par
sd.ests <- estimate.sd(res, df)
#Save sim results to file, so they can readily be retrieved later
if(save.sims)
readr::write_rds(list(ref.data.trun = ref.data.trun, pert.data = pert.data,
grads = grads, cv = cv[i], dist = dist, res = res, par.ests = par.ests,
sd.ests = sd.ests),
path = paste0("./", save.sims.dir, "/cv", i, "_sim", sim, "_res.rds"))
#Vector to return from the foreach
c(par.ests, sd.ests)
}
par.ests <- ests[, 1:length(true.values)]
sd.ests <- ests[, 1:length(true.values) + length(true.values)]
colnames(par.ests) <- colnames(sd.ests) <- names(true.values)
if(save.sims)
write_rds(list(true.values = true.values, par.ests = par.ests, sd.ests = sd.ests),
paste0("./", save.sims.dir, "/cv", i, "_sim_res.rds"))
}
#Stop the timer
toc()
#Stop the cluster
stopCluster(cl)
View(ests)
cv1_sim1_res <- readRDS("~/Academia Yunchen/Gradient matching revisit 2022/SimRes_ests/cv1_sim1_res.rds")
View(cv1_sim1_res)
# Check if the convergence has been met.
con.check <- vector()
warnings()
# Check if the convergence has been met.
con.check <- vector()
for (i in 1:5) {
for (j in 1:200) {
res.temp <- read_rds(paste0("./", save.sims.dir, "/cv", i, "_sim", j, "_res.rds"))
con.temp <- res.temp$res$convergence
con.check <- c(con.check, con.temp)
}
}
which(con.check != 0)
res.dir <- c("SimRes_ests")
cv <- c(0.01, 0.025, 0.05, 0.075, 0.1)
cv.1.res <- read_rds(paste0("./", res.dir, "/cv_1", "_sim_res.rds")")
View(cv1_sim1_res)
View(cv1_sim1_res)
View(cv1_sim1_res)
library(readr)
res.dir <- c("SimRes_ests")
cv <- c(0.01, 0.025, 0.05, 0.075, 0.1)
cv.1.res <- read_rds(paste0("./", res.dir, "/cv_1", "_sim_res.rds")")
cv1_sim_res <- readRDS("~/Academia Yunchen/Gradient matching revisit 2022/SimRes_ests/cv1_sim_res.rds")
cv1_sim_res <- readRDS("~/Academia Yunchen/Gradient matching revisit 2022/SimRes_ests/cv1_sim_res.rds")
View(cv1_sim1_res)
View(cv1_sim_res)
cv1_sim_res[["par.ests"]]
cv.1.res <- read_rds(paste0("./", res.dir, "/cv_1_sim_res.rds"))
cv.1.res <- read_rds(paste0("./", res.dir, "/cv1_sim_res.rds"))
cv.1.res <- read_rds(paste0("./", res.dir, "/cv1_sim_res.rds"))
cv.2.res <- read_rds(paste0("./", res.dir, "/cv2_sim_res.rds"))
cv.3.res <- read_rds(paste0("./", res.dir, "/cv3_sim_res.rds"))
cv.4.res <- read_rds(paste0("./", res.dir, "/cv4_sim_res.rds"))
cv.5.res <- read_rds(paste0("./", res.dir, "/cv5_sim_res.rds"))
cv.1.mean.vals <- apply(cv.1.res$par.ests, 2, mean)
cv.2.mean.vals <- apply(cv.2.res$par.ests, 2, mean)
cv.3.mean.vals <- apply(cv.3.res$par.ests, 2, mean)
cv.4.mean.vals <- apply(cv.4.res$par.ests, 2, mean)
cv.5.mean.vals <- apply(cv.5.res$par.ests, 2, mean)
ests.mat <- rbind(cv.1.mean.vals, cv.2.mean.vals, cv.3.mean.vals,
cv.4.mean.vals, cv.5.mean.vals)
View(ests.mat)
cv.1.true.sd <- apply(cv.1.res$par.ests, 2, sd)
cv.2.true.sd <- apply(cv.2.res$par.ests, 2, sd)
cv.3.true.sd <- apply(cv.3.res$par.ests, 2, sd)
cv.4.true.sd <- apply(cv.4.res$par.ests, 2, sd)
cv.5.true.sd <- apply(cv.5.res$par.ests, 2, sd)
true.sd.mat <- rbind(cv.1.true.sd, cv.2.true.sd, cv.3.true.sd, cv.4.true.sd,
cv.5.true.sd)
View(true.sd.mat)
View(ref.data.trun)
sapply(ref.data.trun, dim)
sum(sapply(ref.data.trun, dim),2 ,prod)
apply(sapply(ref.data.trun, dim), 2, prod)
cv.1.mean.sd <- apply(cv.1.res$sd.ests, 2, mean)
cv.2.mean.sd <- apply(cv.2.res$sd.ests, 2, mean)
cv.3.mean.sd <- apply(cv.3.res$sd.ests, 2, mean)
cv.4.mean.sd <- apply(cv.4.res$sd.ests, 2, mean)
cv.5.mean.sd <- apply(cv.5.res$sd.ests, 2, mean)
mean.sd.mat <- rbind(cv.1.mean.sd, cv.2.mean.sd, cv.3.mean.sd, cv.4.mean.sd,
cv.5.mean.sd)
View(mean.sd.mat)
View(sd.ests)
View(true.sd.mat)
write.table(ests.mat, "Parameter estimates 5 cv.txt")
write.table(ests.mat, "True SD estimates 5 cv.txt")
write.table(true.sd.mat, "True SD estimates 5 cv.txt")
write.table(mean.sd.mat, "Mean SD estimates 5 cv.txt")
#Environment settings
library(readr)
rm(list = ls())
#Environment settings
library(readr)
#Source companion functions
source("PDE_GradientMatching_Functions.r")
# Define model parameters
dn <- 0.01
gamma <- 0.05
eta <- 10
dm <- 0.01
alpha <- 0.1
rn <- 5
# This parameter not included in the optimization
beta <- 0
# Make a vector to store the true values
true.values <- c(dn, gamma, rn, eta, dm, alpha)
names(true.values) <- c("dn", "gamma", "rn", "eta", "dm", "alpha")
#No parameters fixed here, so set fixed par to 6 NAs
fixed.par <- rep(NA, 6)
is.estimated <- is.na(fixed.par)
n.estimated <- sum(is.estimated)
#For optimization, use start values from manuscript
start.values <- c(0.01, 0.133, 6.25, 12.5, 0.0166, 0.125)
#Trim to only those for which parameters are being estimated
start.values <- start.values[is.estimated]
# Define 1D dimensionless space points
n.x11 <- 80
max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
f0 <- 1-0.5*n0
m0 <- 0.5*n0
#Generate reference dataset
ref.data.trun <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0, truncate = TRUE)
### Gradient matching scheme ########
### Author: Yunchen Xiao & Len Thomas ###########
rm(list = ls())
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#Load the package "tictoc" in order to measure the computational time.
library(tictoc)
setwd("~/Academia Yunchen/Gradient matching revisit 2022")
### Gradient matching scheme ########
### Author: Yunchen Xiao & Len Thomas ###########
rm(list = ls())
setwd("~/Academia Yunchen/Gradient matching revisit 2022/No measurement errors")
#Environment settings
library(readr)
#Source companion functions
source("PDE_GradientMatching_Functions.r")
# Define model parameters
dn <- 0.01
gamma <- 0.05
eta <- 10
dm <- 0.01
alpha <- 0.1
rn <- 5
# This parameter not included in the optimization
beta <- 0
# Make a vector to store the true values
true.values <- c(dn, gamma, rn, eta, dm, alpha)
names(true.values) <- c("dn", "gamma", "rn", "eta", "dm", "alpha")
#No parameters fixed here, so set fixed par to 6 NAs
fixed.par <- rep(NA, 6)
is.estimated <- is.na(fixed.par)
n.estimated <- sum(is.estimated)
#For optimization, use start values from manuscript
start.values <- c(0.01, 0.133, 6.25, 12.5, 0.0166, 0.125)
#Trim to only those for which parameters are being estimated
start.values <- start.values[is.estimated]
# Define 1D dimensionless space points
n.x11 <- 80
max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
f0 <- 1-0.5*n0
m0 <- 0.5*n0
#Generate reference dataset
ref.data.trun <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0, truncate = TRUE)
View(ref.data.trun)
#Obtain gradient approximations
dist <- "gamma"
grads <- approximate.gradients(ref.data.trun, x11, max.t, distribution = dist)
write_rds(grads, "Reference gradients GAM.rds")
#Write gradients predicted by GAM into a .txt file
write.table(grads, "Reference gradients GAM.txt")
#Estimate parameter values
res <- optim(start.values, calculate.sse, grads = grads, fixed.par = fixed.par,
control = list(trace = 1, maxit = 20000, reltol = 1e-10))
View(res)
par.ests <- res$par
print(par.ests)
#Environment settings
rm(list = ls())
library(readr)
#Source companion functions
source("PDE_GradientMatching_Functions.r")
# Define model parameters
dn <- 0.01
gamma <- 0.05
eta <- 10
dm <- 0.01
alpha <- 0.1
rn <- 5
# This parameter not included in the optimization
beta <- 0
# Make a vector to store the true values
true.values <- c(dn, gamma, rn, eta, dm, alpha)
names(true.values) <- c("dn", "gamma", "rn", "eta", "dm", "alpha")
#No parameters fixed here, so set fixed par to 6 NAs
fixed.par <- rep(NA, 6)
is.estimated <- is.na(fixed.par)
n.estimated <- sum(is.estimated)
#For optimization, use start values from manuscript
start.values <- c(0.01, 0.133, 6.25, 12.5, 0.0166, 0.125)
#Trim to only those for which parameters are being estimated
start.values <- start.values[is.estimated]
# Define 1D dimensionless space points
n.x11 <- 80
max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
f0 <- 1-0.5*n0
m0 <- 0.5*n0
#Generate reference dataset
ref.data.trun <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0, truncate = TRUE)
View(ref.data.trun)
#Obtain gradient approximations
dist <- "gamma"
grads <- approximate.gradients(ref.data.trun, x11, max.t, distribution = dist)
write_rds(grads, "Reference gradients GAM.rds")
#Write gradients predicted by GAM into a .txt file
write.table(grads, "Reference gradients GAM.txt")
#Estimate parameter values
res <- optim(start.values, calculate.sse, grads = grads, fixed.par = fixed.par,
control = list(trace = 1, maxit = 20000, reltol = 1e-10))
par.ests <- res$par
print(par.ests)
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#readr used to read and write results to file
library(readr)
#Load packages for running the simulation in parallel
library(doParallel)
library(doRNG)
#Directory to read sim results from and write bootstrap results to
save.sims <- TRUE
in.dir <- "SimRes_ests"
save.sims.dir <- "SimRes_boots2"
if(save.sims) {
if(!dir.exists(save.sims.dir)) dir.create(save.sims.dir)
}
setwd("~/Academia Yunchen/Gradient matching revisit 2022")
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#readr used to read and write results to file
library(readr)
#Load packages for running the simulation in parallel
library(doParallel)
library(doRNG)
#Directory to read sim results from and write bootstrap results to
save.sims <- TRUE
rm(list = ls())
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#readr used to read and write results to file
library(readr)
#Load packages for running the simulation in parallel
library(doParallel)
library(doRNG)
#Directory to read sim results from and write bootstrap results to
save.sims <- TRUE
in.dir <- "SimRes_ests"
save.sims.dir <- "SimRes_boots2"
if(save.sims) {
if(!dir.exists(save.sims.dir)) dir.create(save.sims.dir)
}
#Measurement error CVs that were run
cv <- c(0.01, 0.025, 0.05, 0.075, 0.10)
n.cvs <- length(cv)
#Number of bootstrap replicates to calculate SD
B <- 200
#Start values to use for parameters in optim
start.values <- c(0.01, 0.133, 6.25, 12.5, 0.0166, 0.125)
n.pars <- length(start.values)
#Set random number seed so results are reproducible
# (random number set within each level of CV to make any repeat runs of a
#  single CV level easier)
rn.seed <- 762905
#Number of parallel threads to run on
n.threads <- detectCores() - 1
#Number of parallel threads to run on
n.threads <- detectCores()/2
dim.grads <- dim(read_rds(paste0(in.dir, "/cv1_sim1_res.rds"))$grads[[1]])
n.data <- prod(dim.grads)
n.sims <- nrow(read_rds(paste0(in.dir, "/cv1_sim_res.rds"))$par.ests)
boot.res <- matrix(NA, B, n.pars)
cl <- makeCluster(n.threads)
registerDoParallel(cl)
#Set parallel seed - once = TRUE means it's set each time foreach is called
registerDoRNG(rn.seed, once = TRUE)
for(i in 1:n.cvs) {
ests <- foreach (k = 1:n.sims, .combine = rbind) %dopar% {
sim <- readr::read_rds(paste0(in.dir, "/cv", i, "_sim", k, "_res.rds"))
boot.grads <- sim$grads
for (b in 1:B) {
new.dat.ind <- sample.int(n.data, replace = TRUE)
for(l in 1:length(sim$grads))
boot.grads[[l]] <- matrix(as.numeric(sim$grads[[l]])[new.dat.ind],
dim.grads[1], dim.grads[2])
boot.res.temp <- optim(start.values, calculate.sse, grads = boot.grads,
control = list(trace = 1, maxit = 20000))
if (boot.res.temp$convergence > 0) warning("Optim did not converge")
boot.res[b, ] <- boot.res.temp$par
}
readr::write_rds(boot.res, paste0(save.sims.dir, "/cv", i, "_sim", k, "_boot_res.rds"))
boot.mean <- apply(boot.res, 2, mean)
boot.sd <- apply(boot.res, 2, sd)
#Vector to return from the foreach
c(boot.mean, boot.sd)
}
boot.mean <- ests[, 1:n.pars]
boot.sd <- ests[, 1:n.pars + n.pars]
readr::write_rds(list(boot.mean = boot.mean, boot.sd = boot.sd),
paste0(save.sims.dir, "/cv", i, "_boot_res.rds"))
}
#Stop the cluster
stopCluster(cl)
