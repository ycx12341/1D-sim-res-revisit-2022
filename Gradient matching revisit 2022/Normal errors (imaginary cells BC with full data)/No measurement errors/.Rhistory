max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
# Initial values
n <- n0
f0 <- 1-0.5*n0
f <- f0
m0 <- 0.5*n0
m <- m0
#Generate reference dataset
ref.data <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0)
View(ref.data)
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#Generate reference dataset
ref.data.norm.bc <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0)
View(ref.data.norm.bc)
View(ref.data)
ref.data.norm.bc[["n"]]
kkk <- ref.data$n
kkk2 <- ref.data.norm.bc$n
View(kkk)
View(kkk2)
sum((kkk - kkk2)^2)
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#Generate reference dataset
ref.data.norm.bc <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0)
View(ref.data.norm.bc)
View(ref.data)
View(ref.data.norm.bc)
kkk <- ref.data$n
kkk2 <- ref.data.norm.bc$n
View(kkk)
View(kkk2)
sum((kkk - kkk2)^2)
tp[2]
### Gradient matching scheme ########
### Author: Yunchen Xiao & Len Thomas ###########
rm(list = ls())
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#Load the package "tictoc" in order to measure the computational time.
library(tictoc)
#Load "readr" package for writing results - just check it's loaded
#(it's actually used first inside the parallel routine)
library(readr)
#Load packages for running the simulation in parallel
library(doParallel)
library(doRNG)
#Define simulation parameters
#Measurement error CV levels to run (if a scalar then just runs at this one level)
cv <- c(0.01, 0.025, 0.05, 0.075, 0.10)
#Measurement error distribution
dist = "normal"
#Number of simulations at each level of CV
n.sims <- 200
#Whether to save simulation outputs to file or not
# (useful as they are time-consuming to run, and this
# allows further post-processing on results)
save.sims <- TRUE
save.sims.dir <- "SimRes_ests"
#Set random number seed so results are reproducible
# (random number set within each level of CV to make any repeat runs of a
#  single CV level easier)
rn.seed <- 874513
#Number of parallel threads to run on
n.threads <- detectCores() - 1
# Define model parameters
dn <- 0.01
gamma <- 0.05
eta <- 10
dm <- 0.01
alpha <- 0.1
rn <- 5
# This parameter not included in the optimization
beta <- 0
# Make a vector to store the true values
true.values <- c(dn, gamma, rn, eta, dm, alpha)
names(true.values) <- c("dn", "gamma", "rn", "eta", "dm", "alpha")
# Define 1D dimensionless space points
n.x11 <- 80
max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
# Initial values
n <- n0
f0 <- 1-0.5*n0
f <- f0
m0 <- 0.5*n0
m <- m0
#Generate reference dataset
ref.data <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0)
View(ref.data)
### Gradient matching scheme ########
### Author: Yunchen Xiao & Len Thomas ###########
rm(list = ls())
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#Load the package "tictoc" in order to measure the computational time.
library(tictoc)
#Load "readr" package for writing results - just check it's loaded
#(it's actually used first inside the parallel routine)
library(readr)
#Load packages for running the simulation in parallel
library(doParallel)
library(doRNG)
#Define simulation parameters
#Measurement error CV levels to run (if a scalar then just runs at this one level)
cv <- c(0.01, 0.025, 0.05, 0.075, 0.10)
#Measurement error distribution
dist = "normal"
#Number of simulations at each level of CV
n.sims <- 200
#Whether to save simulation outputs to file or not
# (useful as they are time-consuming to run, and this
# allows further post-processing on results)
save.sims <- TRUE
save.sims.dir <- "SimRes_ests"
#Set random number seed so results are reproducible
# (random number set within each level of CV to make any repeat runs of a
#  single CV level easier)
rn.seed <- 874513
#Number of parallel threads to run on
n.threads <- detectCores() - 1
# Define model parameters
dn <- 0.01
gamma <- 0.05
eta <- 10
dm <- 0.01
alpha <- 0.1
rn <- 5
# This parameter not included in the optimization
beta <- 0
# Make a vector to store the true values
true.values <- c(dn, gamma, rn, eta, dm, alpha)
names(true.values) <- c("dn", "gamma", "rn", "eta", "dm", "alpha")
# Define 1D dimensionless space points
n.x11 <- 80
max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
# Initial values
n <- n0
f0 <- 1-0.5*n0
f <- f0
m0 <- 0.5*n0
m <- m0
#Generate reference dataset
ref.data <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0)
data.dim.row <- length(ref.data$n[, 1])
data.dim.col <- length(ref.data$n[1, ])
#Truncate the reference data set to avoid generating gamma errors at data values of 0
ref.data.trun <- list(n = ref.data$n[2:(data.dim.row - 1), 2:(data.dim.col - 1)],
f = ref.data$f[2:(data.dim.row - 1), 2:(data.dim.col - 1)],
m = ref.data$m[2:(data.dim.row - 1), 2:(data.dim.col - 1)])
View(ref.data)
View(ref.data)
### Gradient matching scheme ########
### Author: Yunchen Xiao & Len Thomas ###########
rm(list = ls())
#Source companion functions
source("PDE_GradientMatching_Functions.r")
#Load the package "tictoc" in order to measure the computational time.
library(tictoc)
#Load "readr" package for writing results - just check it's loaded
#(it's actually used first inside the parallel routine)
library(readr)
#Load packages for running the simulation in parallel
library(doParallel)
library(doRNG)
#Define simulation parameters
#Measurement error CV levels to run (if a scalar then just runs at this one level)
cv <- c(0.01, 0.025, 0.05, 0.075, 0.10)
#Measurement error distribution
dist = "normal"
#Number of simulations at each level of CV
n.sims <- 200
#Whether to save simulation outputs to file or not
# (useful as they are time-consuming to run, and this
# allows further post-processing on results)
save.sims <- TRUE
save.sims.dir <- "SimRes_ests"
#Set random number seed so results are reproducible
# (random number set within each level of CV to make any repeat runs of a
#  single CV level easier)
rn.seed <- 874513
#Number of parallel threads to run on
n.threads <- detectCores() - 1
# Define model parameters
dn <- 0.01
gamma <- 0.05
eta <- 10
dm <- 0.01
alpha <- 0.1
rn <- 5
# This parameter not included in the optimization
beta <- 0
# Make a vector to store the true values
true.values <- c(dn, gamma, rn, eta, dm, alpha)
names(true.values) <- c("dn", "gamma", "rn", "eta", "dm", "alpha")
# Define 1D dimensionless space points
n.x11 <- 80
max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
# Initial values
n <- n0
f0 <- 1-0.5*n0
f <- f0
m0 <- 0.5*n0
m <- m0
#Generate reference dataset
ref.data <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0)
View(ref.data)
ref.data[["n"]]
cv1_sim_res <- readRDS("D:/Academia/Gradient matching revisit 2022/Gamma errors (imaginary cells BC)/SimRes_ests/cv1_sim_res.rds")
View(cv1_sim_res)
cv1_sim1_res <- readRDS("D:/Academia/Gradient matching revisit 2022/Gamma errors (imaginary cells BC)/SimRes_ests/cv1_sim1_res.rds")
View(cv1_sim1_res)
cv1_sim1_res <- readRDS("D:/Academia/Data-code-figures-ver-4/Data-Code-Figures-ver-4/Gradient matching/SimRes_ests_converge_check/cv1_sim1_res.rds")
View(cv1_sim1_res)
data.dim.row <- length(ref.data$n[, 1])
data.dim.col <- length(ref.data$n[1, ])
#Truncate the reference data set to avoid generating gamma errors at data values of 0
ref.data.trun <- list(n = ref.data$n[2:(data.dim.row - 1), 2:(data.dim.col - 1)],
f = ref.data$f[2:(data.dim.row - 1), 2:(data.dim.col - 1)],
m = ref.data$m[2:(data.dim.row - 1), 2:(data.dim.col - 1)])
#Use start values from manuscript
start.values <- c(0.01, 0.133, 6.25, 12.5, 0.0166, 0.125)
#Record degrees of freedom for sd calculations
n.data.trun <- sum(apply(sapply(ref.data.trun, dim), 2, prod))
n.params <- length(start.values)
df <- n.data.trun - n.params
setwd("D:/Academia/Gradient matching revisit 2022/Normal errors")
setwd("D:/Academia/Gradient matching revisit 2022/Normal errors")
#Introduce random error
pert.data <- perturb.reference.data(ref.data.trun, cv = 0.01, distribution = dist)
View(pert.data)
#Introduce random error
pert.data <- perturb.reference.data(ref.data, cv = 0.01, distribution = dist)
View(pert.data)
which(pert.data$n == 0)
which(pert.data$n < 0)
which(pert.data$f < 0)
which(pert.data$m < 0)
View(pert.data)
data <- pert.data
#Space discretization for calculating derivatives is set by data spacing
# (but need not be)
h <- x11[2] - x11[1]
#Time discretization for calculating derivatives is set manually
dt <- 0.001
#Transform each time series into a data frame
n.x11 <- length(x11)
tp <- seq(0, max.t, by = 1)
dat_n <- data.frame(n = as.vector(data$n), t = rep(tp, times = n.x11),
x11 = rep(x11, each = length(tp)))
dat_f <- data.frame(f = as.vector(data$f), t = rep(tp, times = n.x11),
x11 = rep(x11, each = length(tp)))
dat_m <- data.frame(m = as.vector(data$m), t = rep(tp, times = n.x11),
x11 = rep(x11, each = length(tp)))
View(dat_n)
distribution <- "normal"
#Fit a gam to each time series
if(distribution == "gamma") {
fam <- Gamma(link = "log")
} else {
if(distribution == "normal") {
fam <- gaussian(link = "identity")
} else {
stop("Distribution not one of gamma or normal\n")
}
}
View(fam)
suppressWarnings(spl <- gam(n ~ s(t, x11, bs = "ad"), family = fam, data = dat_n))
#mgcv package required for fitting gams
require(mgcv)
suppressWarnings(spl <- gam(n ~ s(t, x11, bs = "ad"), family = fam, data = dat_n))
suppressWarnings(spl2 <- gam(f ~ s(t, x11, bs = "ad"), family = fam, data = dat_f))
suppressWarnings(spl3 <- gam(m ~ s(t, x11, bs = "ad"), family = fam, data = dat_m))
#Prepare to calculate the required gradients
dim_row <- length(data$n[, 1])
dim_col <- length(data$f[1, ])
# Temporal gradients of ECM.
grad_lhs_f_data <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_f_t1 <- predict(spl2, newdata = data.frame(t = tp[i + 1] + dt, x11 = x11[j + 1]),
type = "response")
predict_f_t2 <- predict(spl2, newdata = data.frame(t = tp[i + 1] - dt, x11 = x11[j + 1]),
type = "response")
grad_lhs_f_data[i,j] <- (predict_f_t1 - predict_f_t2) / (2 * dt)
}
}
View(spl)
# Spatial gradients of ECM.
grad_rhs_f_ita <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_f <- predict(spl2, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
predict_m <- predict(spl3, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
grad_rhs_f_ita[i, j] <- predict_f * predict_m
}
}
# Temporal gradients of MDE.
grad_lhs_m_data <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_m_t1 <- predict(spl3, newdata = data.frame(t = tp[i + 1] + dt, x11 = x11[j + 1]),
type = "response")
predict_m_t2 <- predict(spl3, newdata = data.frame(t = tp[i + 1] - dt, x11 = x11[j + 1]),
type = "response")
grad_lhs_m_data[i,j] <- (predict_m_t1 - predict_m_t2) / (2 * dt)
}
}
# Spatial gradients of MDE.
grad_rhs_m_dm <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_x1 <- predict(spl3, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1] - h),
type = "response")
predict_x2 <- predict(spl3, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
predict_x3 <- predict(spl3, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1] + h),
type = "response")
grad_rhs_m_dm[i, j] <- (predict_x3 + predict_x1 - 2 * predict_x2) / (h ^ 2)
}
}
grad_rhs_m_alpha <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_n <- predict(spl, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
grad_rhs_m_alpha[i, j] <- predict_n
}
}
# Temporal gradients of tumour cells.
grad_lhs_n_data <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_n_t1 <- predict(spl, newdata = data.frame(t = tp[i + 1] + dt, x11 = x11[j + 1]),
type = "response")
predict_n_t2 <- predict(spl, newdata = data.frame(t = tp[i + 1] - dt, x11 = x11[j + 1]),
type = "response")
grad_lhs_n_data[i,j] <- (predict_n_t1 - predict_n_t2) / (2 * dt)
}
}
# Spatial gradients of tumour cells.
grad_rhs_n_dn <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_x1 <- predict(spl, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1] - h),
type = "response")
predict_x2 <- predict(spl, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
predict_x3 <- predict(spl, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1] + h),
type = "response")
grad_rhs_n_dn[i, j] <- (predict_x3 + predict_x1 - 2 * predict_x2) / (h ^ 2)
}
}
grad_rhs_n_gamma <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_x1_n <- predict(spl, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1] - h),
type = "response")
predict_x2_n <- predict(spl, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
predict_x3_n <- predict(spl, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1] + h),
type = "response")
predict_n.dash <- (predict_x3_n - predict_x1_n) / (2 * h)
predict_x1_f <- predict(spl2, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1] - h),
type = "response")
predict_x2_f <- predict(spl2, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
predict_x3_f <- predict(spl2, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1] + h),
type = "response")
predict_f.dash <- (predict_x3_f - predict_x1_f) / (2 * h)
predict_f.ddash <- (predict_x3_f + predict_x1_f - 2 * predict_x2_f) / (h ^ 2)
grad_rhs_n_gamma[i, j] <- predict_n.dash * predict_f.dash + predict_x2_n * predict_f.ddash
}
}
grad_rhs_n_r <- matrix(0, (dim_row - 2), (dim_col - 2))
for (i in 1:(dim_row - 2)) {
for (j in 1:(dim_col - 2)) {
predict_n <- predict(spl, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
predict_f <- predict(spl2, newdata = data.frame(t = tp[i + 1], x11 = x11[j + 1]),
type = "response")
grad_rhs_n_r[i, j] <- predict_n*(1-predict_n-predict_f)
}
}
setwd("D:/Academia/Gradient matching revisit 2022/Normal errors/No measurement errors")
#Environment settings
rm(list = ls())
library(readr)
#Source companion functions
source("PDE_GradientMatching_Functions.r")
# Define model parameters
dn <- 0.01
gamma <- 0.05
eta <- 10
dm <- 0.01
alpha <- 0.1
rn <- 5
# This parameter not included in the optimization
beta <- 0
# Make a vector to store the true values
true.values <- c(dn, gamma, rn, eta, dm, alpha)
names(true.values) <- c("dn", "gamma", "rn", "eta", "dm", "alpha")
#No parameters fixed here, so set fixed par to 6 NAs
fixed.par <- rep(NA, 6)
is.estimated <- is.na(fixed.par)
n.estimated <- sum(is.estimated)
#For optimization, use start values from manuscript
start.values <- c(0.01, 0.133, 6.25, 12.5, 0.0166, 0.125)
#Trim to only those for which parameters are being estimated
start.values <- start.values[is.estimated]
# Define 1D dimensionless space points
n.x11 <- 80
max.x11 <- 1
x11 <- seq(0, max.x11, length = n.x11)
# Define time discretization and max time
dt <- 0.001
max.t <- 10
# Set initial conditions
eps <- 0.01
n0 <- rep(0, n.x11)
for (i in 1:n.x11) {
if (x11[i] <= 0.25) {
n0[i] <- exp(-x11[i] ^ 2 / eps)
} else {
n0[i] <- 0
}
}
f0 <- 1-0.5*n0
m0 <- 0.5*n0
#Generate reference dataset
ref.data <- generate.reference.data(n.x11, max.x11, dt, max.t,
dn, gamma, eta, dm, alpha, rn, beta, n0, f0, m0, truncate = FALSE)
#Obtain gradient approximations
dist <- "normal"
grads <- approximate.gradients(ref.data.trun, x11, max.t, distribution = dist)
View(ref.data)
grads <- approximate.gradients(ref.data, x11, max.t, distribution = dist)
write_rds(grads, "Reference gradients GAM.rds")
#Write gradients predicted by GAM into a .txt file
write.table(grads, "Reference gradients GAM.txt")
#Estimate parameter values
res <- optim(start.values, calculate.sse, grads = grads, fixed.par = fixed.par,
control = list(trace = 1, maxit = 20000, reltol = 1e-10))
par.ests <- res$par
print(par.ests)
#Calculate percent error
perc.err <- (par.ests - true.values) / true.values * 100
print(perc.err)
